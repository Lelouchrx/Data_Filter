# Automated Video Quality & Content Filtering System

This project is a client-server based pipeline designed to automatically filter video datasets for robotics learning or computer vision tasks. It utilizes a two-stage screening process to filter out low-quality videos (blur, shake, bad exposure) and videos lacking specific content (hand-object interaction).

## âœ¨ Key Features

* **Two-Stage Analysis Pipeline**:
1. **Quality Filter**: fast pre-screening for blur, camera jitter/shake, and exposure issues.
2. **Content Filter**: AI-based detection (YOLO + Depth Anything) to verify valid hand-object interactions.


* **Automatic Sorting**: processed videos are automatically moved to `server_data/accepted_videos` or `server_data/rejected_videos`. **No data is deleted.**
* **Comprehensive Logging**: detailed JSON analysis reports are generated for every single video.
* **Smart Batch Processing**: the client supports recursive directory scanning, automatic error handling, and batch summary statistics.
* **High Performance**: server-side models are pre-loaded into GPU memory for fast inference.

## ğŸ“‚ Project Structure

```text
project_root/
â”œâ”€â”€ blur/                   # [Core] Quality detection algorithms (blur/jitter/exposure)
â”œâ”€â”€ data_filtering/         # [Core] Content detection algorithms (YOLO/HOI System)
â”œâ”€â”€ server_data/            # [Auto-Generated] Server storage
â”‚   â”œâ”€â”€ temp_uploads/       # Temporary staging area
â”‚   â”œâ”€â”€ accepted_videos/    # âœ… High-quality videos with interaction
â”‚   â”œâ”€â”€ rejected_videos/    # ğŸš« Low-quality or non-interactive videos
â”‚   â””â”€â”€ processing_logs/    # ğŸ“ JSON result logs
â”œâ”€â”€ server.py               # FastAPI Server script
â”œâ”€â”€ client.py               # Client script (English CLI)
â””â”€â”€ requirements.txt        # Dependencies

```

## ğŸ› ï¸ Prerequisites & Installation

Recommended: Python 3.10+ and a CUDA-capable GPU.

1. **Install Dependencies**:
```bash
pip install fastapi uvicorn python-multipart requests opencv-python numpy ultralytics torch

```


*(Note: Ensure you have the necessary libraries for the `blur` and `data_filtering` modules as well, such as `tqdm`, `matplotlib`, `pyyaml`, etc.)*

## ğŸš€ Usage Guide

### 1. Start the Server

The server handles model loading, inference, and file management.

```bash
python server.py

```

* **Startup**: Wait until you see `âœ… [Server] model loaded successfully` (Model loaded) and `Uvicorn running on http://0.0.0.0:8000`.
* **First Run**: The system may download YOLO/Depth weights automatically on the first launch.

### 2. Run the Client

The client uploads videos and displays real-time analysis results.

**Option A: Process a Single File**

```bash
python client.py /path/to/video.mp4
python client.py "client files"
```

**Option B: Batch Process a Folder (Recommended)**
Recursively scans the directory for video files (`.mp4`, `.mov`, `.avi`, etc.).

```bash
python client.py /path/to/dataset_folder/

```

## ğŸ“Š Outputs & Logs

### Client Console

After processing, the client displays a summary dashboard:

```text
========================================
ğŸ“Š Batch Processing Completed (45.2s)
========================================
Total Videos:       10
âœ… Accepted:         3
ğŸš« Quality Fail:     5
âš ï¸ Content Fail:     2
âŒ Errors:           0
========================================

```

### Server Storage (`server_data/`)

* **`accepted_videos/`**: Contains the "clean" dataset ready for training.
* **`rejected_videos/`**: Contains videos that failed checks (kept for auditing).
* **`processing_logs/`**: JSON files containing detailed metrics. Example:
```json
{
    "filename": "demo.mp4",
    "pipeline_status": "ACCEPTED",
    "quality_data": {
        "blur_score": 214.5,
        "is_shake": false,
        "jitter_disp_pct": 2.1
    },
    "content_data": {
        "interaction_ratio": 0.95,
        "missing_hand_ratio": 0.0
    }
}

```



## âš™ï¸ Configuration

* **Server Port**: Modify the `uvicorn.run(..., port=8000)` line in `server.py`.
* **Thresholds**: Adjust quality or interaction thresholds inside the `analyze_video_endpoint` function in `server.py` (e.g., `threshold=100.0`, `video_blur_ratio=0.3`).

## âš ï¸ Notes

1. **GPU Memory**: The server keeps models loaded in VRAM. Ensure you have at least 4GB VRAM available (depending on model size).
2. **Concurrency**: The current implementation handles requests sequentially to ensure GPU stability.
3. **Temporary Files**: The `temp_uploads` folder is self-cleaning. Files are moved out immediately after processing.